{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder-UNetBased-LiDAR_Data_Compression",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOU+iPWXoKJfcnJNzRxi4Bp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunWenlu/-/blob/master/AutoEncoder_UNetBased_LiDAR_Data_Compression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1st round of training a (Variational)AutoEncoder on LiDAR statistics**\n",
        "Date: 20/06/2022\n",
        "Wenlu Sun"
      ],
      "metadata": {
        "id": "XAJdjjkYxAc_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYAoikGRNt7f"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "# Load the sample data from personal Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "Project_Path = \"/content/drive/MyDrive/TUM/\"\n",
        "# sample1_Path is regraded as training data\n",
        "sample1_Path = \"/content/drive/MyDrive/TUM/sam-1-1647360000_19571765_4ee45dac0acf65d7db1dac9aebb54bc3/\"\n",
        "# sample1_Path is regraded as testing data\n",
        "sample2_Path = \"/content/drive/MyDrive/TUM/sam-2-1648137600_35424916_c2e49754aa5b577c06c6d685ee45e7a6/\"\n",
        "os.chdir(sample1_Path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2\n",
        "import keras\n",
        "from PIL import Image\n",
        "from skimage import data, io, filters\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import manifold, datasets\n",
        "import glob\n",
        "from keras.preprocessing import image\n",
        "import gdal\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate\n",
        "import torch\n",
        "import torchvision\n",
        "from keras.callbacks import TensorBoard"
      ],
      "metadata": {
        "id": "XookCYmo3nBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3\n",
        "# Multi channel images loading ## 多channel图像读取\n",
        "# Read image pixel matrix ## 读取图像像素矩阵\n",
        "# fileName: name of the .tiff image\n",
        "def readTif(fileName):\n",
        "    dataset = gdal.Open(fileName)\n",
        "    width = dataset.RasterXSize\n",
        "    height = dataset.RasterYSize\n",
        "    GdalImg_data = dataset.ReadAsArray(0, 0, width, height)\n",
        "    return GdalImg_data"
      ],
      "metadata": {
        "id": "00L4IiLe9_LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4\n",
        "# # This step was designed to convert the .tiff format into .jpg, etc. \n",
        "# # Besides, it can also be used to check the contents of the file and the image size\n",
        "# # Utilization: Select all then uncomment\n",
        "# n=14 #number of images at same area\n",
        "\n",
        "# # Read all imgs in training data file \n",
        "# paths = glob.glob(os.path.join(sample1_Path,'*.tiff'))\n",
        "# print(paths,sample1_Path)\n",
        "# for i in paths:\n",
        "# \tpath= i \n",
        "# \timg= io.imread(path)\n",
        "\n",
        "# \t#Subsection of the image\n",
        "# \t#img=img[52:308,52:308]\n",
        "# \tprint (img.shape)\n",
        "# \treadTif(path)\n",
        "# \t#io.imsave(path+'.jpg',img)\n",
        "\n",
        "# # Read all imgs in testing data file\n",
        "# paths_test = glob.glob(os.path.join(sample2_Path,'*.tiff'))\n",
        "# print(paths,sample2_Path)\n",
        "# for j in paths:\n",
        "# \tpath= j \n",
        "# \timg= io.imread(path)\n",
        "\t\n",
        "# \t#Subsection of the image\n",
        "# \t#img=img[52:308,52:308]\n",
        "# \tprint (img.shape)\n",
        "# \treadTif(path)\n",
        "# \t# Test_Img[k].append(readTif(path))\n",
        "# \t#io.imsave(path+'.jpg',img)\n"
      ],
      "metadata": {
        "id": "tyySTbgCN8y9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5\n",
        "# Read the 13 imgs with sepcific order\n",
        "key = [\"Elevation Local Mean\",\"Elevation Local Maximum\",\"Elevation Local Minimum\",\"Elevation Local Std\",\"Elevation Local Count\",\n",
        "       \"Reflectance Local Mean\",\"Reflectance Local Maximum\",\"Reflectance Local Minimum\",\"Reflectance Local Std\",\n",
        "       \"Return Count Local Mean\", \"Return Count Local Maximum\",\"Return Count Local Minimum\",\"Return Count Local Std\"];"
      ],
      "metadata": {
        "id": "NxgoOQSm6Dxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "# Create Training data ## 创建训练数据\n",
        "def create_train_data(sample1_Path):\n",
        "  i = 0\n",
        "  print('-'*30)\n",
        "  print('Creating training images...')\n",
        "  print('-'*30)\n",
        "  imgs = glob.glob(os.path.join(sample1_Path,'*.tiff'))\n",
        "  # imgs.sort(key=lambda x: int(x.split('/')[3][:-4])) # the order was defined according to \"key\", might be changed later\n",
        "  print(len(imgs))\n",
        "  # print(imgs)\n",
        "\n",
        "  imgdatas = np.ndarray((len(imgs)-1,544,544,1), dtype=np.uint8) #############\n",
        "\n",
        "  for key_item in key:\n",
        "    for imgname in imgs:\n",
        "      # midname = imgname[imgname.rindex(\"/\")+1:]\n",
        "      # if 'Landsat' in imgname:\n",
        "      #   # i += 1\n",
        "      #   # print('yes',imgname)\n",
        "      #   continue\n",
        "      # else:\n",
        "      if key_item in imgname:\n",
        "        img = image.load_img(imgname, color_mode='grayscale')\n",
        "        print(i, imgname)\n",
        "        img = image.img_to_array(img)\n",
        "        imgdatas[i] = img\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "  print('loading done')\n",
        "  # imgdatas = imgdatas.swapaxes(0, 1)\n",
        "  # imgdatas = imgdatas.swapaxes(1, 2)\n",
        "  # imgdatas = imgdatas.swapaxes(2,3)\n",
        "  # img = img.swapaxes(2, 3)\n",
        "  np.save(sample1_Path + '/imgs_train.npy', imgdatas)\n",
        "  \n",
        "  # np.save(self.npy_path + '/imgs_mask_train.npy', imglabels)\n",
        "  print('Saving to .npy files done.')\n",
        "  print(imgdatas.shape)"
      ],
      "metadata": {
        "id": "Q50pu32bYXPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7\n",
        "# Create Testing data ## 创建训练数据\n",
        "def create_test_data(sample1_Path):\n",
        "  \n",
        "  i = 0\n",
        "  print('-'*30)\n",
        "  print('Creating testing images...')\n",
        "  print('-'*30)\n",
        "  imgs = glob.glob(os.path.join(sample2_Path,'*.tiff'))\n",
        "  # imgs.sort(key=lambda x: int(x.split('/')[3][:-4])) # the order was defined according to \"key\", might be changed later\n",
        "  print(len(imgs))\n",
        "  # print(imgs)\n",
        "\n",
        "  imgdatas = np.ndarray((len(imgs)-1,544,544,1), dtype=np.uint8) #############\n",
        "\n",
        "  for key_item in key:\n",
        "\n",
        "    for imgname in imgs:\n",
        "      # midname = imgname[imgname.rindex(\"/\")+1:]\n",
        "      # if 'Landsat' in imgname:\n",
        "      #   # i += 1\n",
        "      #   # print('yes')\n",
        "      #   continue\n",
        "      # else:\n",
        "        ##########################\n",
        "      if key_item in imgname:\n",
        "        img = image.load_img(imgname, color_mode='grayscale')\n",
        "        print(i,imgname)\n",
        "\n",
        "        # print(\"*\")\n",
        "\n",
        "        img = image.img_to_array(img)\n",
        "        imgdatas[i] = img\n",
        "\n",
        "        continue\n",
        "\n",
        "  print('loading done')\n",
        "  # imgdatas = imgdatas.swapaxes(0, 1)\n",
        "  # imgdatas = imgdatas.swapaxes(1, 2)\n",
        "  # imgdatas = imgdatas.swapaxes(2,3)\n",
        "  # img = img.swapaxes(2, 3)\n",
        "  np.save(sample2_Path + '/imgs_test.npy', imgdatas)\n",
        "  print('Saving to .npy files done.')\n",
        "  print(imgdatas.shape)\n"
      ],
      "metadata": {
        "id": "yfj-zJ0rt5uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8\n",
        "create_train_data(sample1_Path)\n",
        "# print(imgdatas.shape)"
      ],
      "metadata": {
        "id": "6o9eP7nMZUbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9\n",
        "create_test_data(sample2_Path)\n",
        "# print(imgdatas.shape)"
      ],
      "metadata": {
        "id": "C5-kszmKuFi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10\n",
        "# Load training data ## 加载训练图片与mask\n",
        "def load_train_data(self_path):\n",
        "  '''\n",
        "    return: the .npy data of training images, format supposed to be: (13,544,544,1)\n",
        "  '''\n",
        "  print('-'*30)\n",
        "  print('load train images...')\n",
        "  print('-'*30)\n",
        "\n",
        "  imgs_train = np.load(self_path+\"/imgs_train.npy\")\n",
        "  imgs_train = imgs_train.astype('float32')\n",
        "  imgs_train /= 255\n",
        "# denoising if necessiary\n",
        "  # mean = imgs_train.mean(axis = 0)\n",
        "  # imgs_train -= mean\n",
        "\n",
        "  return imgs_train"
      ],
      "metadata": {
        "id": "Hqsr9b0vcpaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11\n",
        "# Load testing data ## 加载训练图片与mask\n",
        "def load_test_data(self_path):\n",
        "    '''\n",
        "    return: the .npy data of testing images, format supposed to be: (13,544,544,1)\n",
        "  '''\n",
        "  print('-'*30)\n",
        "  print('load test images...')\n",
        "  print('-'*30)\n",
        "  imgs_test = np.load(self_path+\"/imgs_test.npy\")\n",
        "  # imgs_mask_test = np.load(self.npy_path+\"/imgs_mask_test.npy\")\n",
        "  imgs_test = imgs_test.astype('float32')\n",
        "  # imgs_mask_test = imgs_mask_test.astype('float32')\n",
        "  imgs_test /= 255\n",
        "  # mean = imgs_test.mean(axis = 0)\n",
        "  # imgs_test -= mean\n",
        "  # imgs_mask_test /= 255\n",
        "  # imgs_mask_test[imgs_mask_test > 0.5] = 1\n",
        "  # imgs_mask_test[imgs_mask_test <= 0.5] = 0\n",
        "  return imgs_test\n",
        "\n"
      ],
      "metadata": {
        "id": "kQxrKf9-uOon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12\n",
        "X_train = load_train_data(sample1_Path)\n",
        "print(X_train.shape)"
      ],
      "metadata": {
        "id": "uQDItdJtc4Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 13\n",
        "X_test = load_test_data(sample2_Path)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "8WoVibG_UueM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 14\n",
        "# Define convolutional block\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)  #Not in the original network\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "aXlyD1bwZf_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15\n",
        "# Define Encoder block\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p"
      ],
      "metadata": {
        "id": "TnojbiGbZgI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 16\n",
        "# Define Decoder block\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x"
      ],
      "metadata": {
        "id": "BI18EwpJZxBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 17\n",
        "# Build UNet-like Autoencoder Architecture\n",
        "def build_unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "    n_classes = 1\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024) #Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    if n_classes == 1:\n",
        "      activation = 'sigmoid'\n",
        "    else:\n",
        "      activation = 'softmax'\n",
        "\n",
        "    outputs = Conv2D(n_classes, 1, padding=\"same\", activation=activation)(d4)  \n",
        "\n",
        "    model = Model(inputs,outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "Li7kdwF1ZxJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 18\n",
        "# build and show the structure of the network\n",
        "# Attention: need to change the input image size ########################################\n",
        "input_img = shape=(544,544,1)### 1 band, grayscale\n",
        "my_unet = build_unet(input_shape=(544,544,1))\n",
        "print(my_unet.summary())"
      ],
      "metadata": {
        "id": "pFzRrwtUZxPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 19\n",
        "# Compile the designed UNet-like AutoEncoder\n",
        "my_unet.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "IfyxAVLoZgMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 20\n",
        "# Check the format of training and testing data\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "FP_ESNYaTC9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 21\n",
        "# Loss function designed part, in this case I chose binary crossentropy, but the reconstruction loss might be considered later.\n",
        "# reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
        "# reconstruction_loss *= original_dim\n",
        "# kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "# kl_loss = K.sum(kl_loss, axis=-1)\n",
        "# kl_loss *= -0.5\n",
        "# vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "# vae.add_loss(vae_loss)\n",
        "# vae.compile(optimizer='adam')"
      ],
      "metadata": {
        "id": "Wbgqg5GBrI1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 22\n",
        "# X_train = X_train.astype('float32') \n",
        "print(X_train.max()) # make sure that the input pixel ranged within (0,1)\n",
        "# X_test = X_test.astype('float32') / 255."
      ],
      "metadata": {
        "id": "Xj63r_PbkCYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 23\n",
        "# Train the model\n",
        "# Attention: it may take serveral minuten, for Colab the batch_size cannot be setted too large, and the epochs could be larger, such as 20, 50, ...) \n",
        "# Question might affect the result: the setup of the training parameters. \n",
        "history = my_unet.fit(X_train, X_train,\n",
        "                epochs=50,\n",
        "                batch_size=5, verbose=1,shuffle=True,\n",
        "                validation_data=(X_test,X_test))####### test data\n"
      ],
      "metadata": {
        "id": "9ufmFMJlZgQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 24\n",
        "# list all data in model\n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize model for loss, visulization the loss and val_loss value\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LWzo7hhlZ5Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25\n",
        "# summarize model for accuracy and val_accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oKg1WD7rb9GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################### Training Part is done ##########################"
      ],
      "metadata": {
        "id": "tnQq2nf2TsxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 26\n",
        "# Save the model to Google Cloud Drive\n",
        "PATH = '/content/drive/MyDrive/TUM/tran_Test-Equal-To-Train.pth'\n",
        "torch.save(my_unet, PATH)\n"
      ],
      "metadata": {
        "id": "eY0HBJHMfbmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 27\n",
        "# Reload the above trained model \n",
        "PATH = '/content/drive/MyDrive/TUM/tran_Test-Equal-To-Train.pth'\n",
        "my_unet = torch.load(PATH)\n"
      ],
      "metadata": {
        "id": "Yd5pLnrefe_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 28\n",
        "# Predict on another dataset \n",
        "# Attention: it may take several minutes, if you use Google Colab Notebook pls make sure your internet connection is stable.  !\n",
        "decoded_imgs = my_unet.predict(X_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "Co2Oq2-HsE4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 29\n",
        "# Checkt the format of the predicted data \n",
        "print(decoded_imgs.shape)"
      ],
      "metadata": {
        "id": "G7Y-scQnqvaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 30\n",
        "# Show the initial and predicted results\n",
        "n = 13\n",
        "\n",
        "plt.figure(figsize=(20,4))\n",
        "for i in range(0, X_train.shape[0]): #n\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, 1+i)\n",
        "    ax.imshow(X_train[i,:,:,0],cmap = 'gray')\n",
        "    # cv2.imwrite(str(i)+\".png\",image[i,:,:])\n",
        "    # plt.show()\n",
        "    # ax.imshow(img[:,:,0], cmap='gray')\n",
        "\n",
        "    # plt.imshow(X_test.reshape(28, 28))\n",
        "    # plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i+1 + n)\n",
        "    plt.imshow(decoded_imgs[i,:,:,0],cmap = 'gray')\n",
        "    # plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    # plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    \n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gqz_xavIujUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# Test Code is done here ##############################"
      ],
      "metadata": {
        "id": "4vrzTzhITs9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# Below is the structure of the complete UNet architecture (Not an Autoencoder but for Classification) ##############################"
      ],
      "metadata": {
        "id": "PxYDF50j73R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "class automaticmaplabelling():\n",
        "    def __init__(self,modelPath,full_chq,imagePath,width,height,channels):\n",
        "        print (modelPath)\n",
        "        print(imagePath)\n",
        "        print(width)\n",
        "        print(height)\n",
        "        print(channels)\n",
        "        self.modelPath=modelPath\n",
        "        self.full_chq=full_chq\n",
        "        self.imagePath=imagePath\n",
        "        self.IMG_WIDTH=width\n",
        "        self.IMG_HEIGHT=height\n",
        "        self.IMG_CHANNELS=channels\n",
        "        self.model = self.U_net()\n",
        "        \n",
        "    def mean_iou(self,y_true, y_pred):\n",
        "        prec = []\n",
        "        for t in np.arange(0.5, 1.0, 0.05):\n",
        "            y_pred_ = tf.to_int32(y_pred > t)\n",
        "            score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "            K.get_session().run(tf.local_variables_initializer())\n",
        "            with tf.control_dependencies([up_opt]):\n",
        "                score = tf.identity(score)\n",
        "            prec.append(score)\n",
        "        return K.mean(K.stack(prec), axis=0)\n",
        "\n",
        "    def U_net(self):\n",
        "        # Build U-Net model\n",
        "        inputs = Input((self.IMG_HEIGHT, self.IMG_WIDTH, self.IMG_CHANNELS))\n",
        "        s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "        c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
        "        c1 = Dropout(0.1) (c1)\n",
        "        c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "        p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "        c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "        c2 = Dropout(0.1) (c2)\n",
        "        c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "        p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "        c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "        c3 = Dropout(0.2) (c3)\n",
        "        c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "        p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "        c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "        c4 = Dropout(0.2) (c4)\n",
        "        c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "        p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "        c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "        c5 = Dropout(0.3) (c5)\n",
        "        c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "        u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "        u6 = concatenate([u6, c4])\n",
        "        c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "        c6 = Dropout(0.2) (c6)\n",
        "        c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "        u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "        u7 = concatenate([u7, c3])\n",
        "        c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "        c7 = Dropout(0.2) (c7)\n",
        "        c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "        u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "        u8 = concatenate([u8, c2])\n",
        "        c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "        c8 = Dropout(0.1) (c8)\n",
        "        c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "        u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "        u9 = concatenate([u9, c1], axis=3)\n",
        "        c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "        c9 = Dropout(0.1) (c9)\n",
        "        c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "        outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "        model = Model(inputs=[inputs], outputs=[outputs])\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[self.mean_iou])\n",
        "        model.load_weights(self.modelPath)\n",
        "        model.summary()\n",
        "        return model\n",
        "\n",
        "    def prediction(self):\n",
        "        img=cv2.imread(self.imagePath,0)\n",
        "        img=np.expand_dims(img,axis=-1)\n",
        "        x_test= np.zeros((1, self.IMG_HEIGHT, self.IMG_WIDTH, self.IMG_CHANNELS), dtype=np.uint8)\n",
        "        #testimg=resize(img,(self.IMG_HEIGHT,self.IMG_WIDTH),mode='constant',preserve_range=True)\n",
        "        x_test[0]=img\n",
        "        preds_test= self.model.predict(x_test, verbose=1)\n",
        "        \n",
        "        preds_test = (preds_test > 0.5).astype(np.uint8)\n",
        "        mask=preds_test[0]\n",
        "        for i in range(mask.shape[0]):\n",
        "            for j in range(mask.shape[1]):\n",
        "                if mask[i][j] == 1:\n",
        "                    mask[i][j] = 255\n",
        "                else:\n",
        "                    mask[i][j] = 0\n",
        "        merged_image = cv2.merge((mask,mask,mask))\n",
        "        contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
        "        for each_contour in contours:\n",
        "            x,y,w,h = cv2.boundingRect(each_contour)\n",
        "\n",
        "            cv2.rectangle(merged_image,(x,y),(x+w,y+h),(0,0,255),4)\n",
        "\n",
        "            print (x,y,w,h)\n",
        "            cv2.imshow(\"merged_image\",merged_image)\n",
        "            cv2.waitKey(0)\n",
        "        \n",
        "        cv2.imwrite(\"mask.png\",mask)\n",
        "\n",
        "        return x_test[0],mask\n",
        "\n",
        "def main():\n",
        "    test_image_name = \"Lidar-NYC LiDAR Return Count Local Mean[count_mean]-01_01_2017T00_00_00.tiff\"\n",
        "    automaticmaplabellingobj= automaticmaplabelling('model-dsbowl2018-1.h5',True,test_image_name,128,128,3)\n",
        "    testimg,mask = automaticmaplabellingobj.prediction()\n",
        "    print('Showing images..')\n",
        "    cv2.imshow('img',testimg)\n",
        "    dim = (544, 544)\n",
        "    resized = cv2.resize(mask, dim, interpolation = cv2.INTER_AREA)\n",
        "    \n",
        "    cv2.imshow('mask',mask)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    cv2.imwrite(\"resized_mask.png\",resized)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ZHkgpLeyZQoz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}